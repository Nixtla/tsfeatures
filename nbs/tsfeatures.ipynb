{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features\n",
    "\n",
    "> Fill in a module description here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp tsfeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import os\n",
    "import warnings\n",
    "from collections import ChainMap\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "warnings.warn = lambda *a, **kw: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from itertools import groupby\n",
    "from math import e  # maybe change with numpy e\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from antropy import spectral_entropy\n",
    "from arch import arch_model\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import acf, kpss, pacf\n",
    "from supersmoother import SuperSmoother\n",
    "\n",
    "from tsfeatures.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def acf_features(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Calculates autocorrelation function features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'x_acf1': First autocorrelation coefficient.\n",
    "        'x_acf10': Sum of squares of first 10 autocorrelation coefficients.\n",
    "        'diff1_acf1': First autocorrelation ciefficient of differenced series.\n",
    "        'diff1_acf10': Sum of squared of first 10 autocorrelation coefficients\n",
    "                       of differenced series.\n",
    "        'diff2_acf1': First autocorrelation coefficient of twice-differenced series.\n",
    "        'diff2_acf10': Sum of squared of first 10 autocorrelation coefficients of\n",
    "                       twice-differenced series.\n",
    "\n",
    "        Only for seasonal data (freq > 1).\n",
    "        'seas_acf1': Autocorrelation coefficient at the first seasonal lag.\n",
    "    \"\"\"\n",
    "    m = freq\n",
    "    size_x = len(x)\n",
    "\n",
    "    acfx = acf(x, nlags=max(m, 10), fft=False)\n",
    "    if size_x > 10:\n",
    "        acfdiff1x = acf(np.diff(x, n=1), nlags=10, fft=False)\n",
    "    else:\n",
    "        acfdiff1x = [np.nan] * 2\n",
    "\n",
    "    if size_x > 11:\n",
    "        acfdiff2x = acf(np.diff(x, n=2), nlags=10, fft=False)\n",
    "    else:\n",
    "        acfdiff2x = [np.nan] * 2\n",
    "    # first autocorrelation coefficient\n",
    "\n",
    "    try:\n",
    "        acf_1 = acfx[1]\n",
    "    except:\n",
    "        acf_1 = np.nan\n",
    "\n",
    "    # sum of squares of first 10 autocorrelation coefficients\n",
    "    sum_of_sq_acf10 = np.sum((acfx[1:11]) ** 2) if size_x > 10 else np.nan\n",
    "    # first autocorrelation ciefficient of differenced series\n",
    "    diff1_acf1 = acfdiff1x[1]\n",
    "    # sum of squared of first 10 autocorrelation coefficients of differenced series\n",
    "    diff1_acf10 = np.sum((acfdiff1x[1:11]) ** 2) if size_x > 10 else np.nan\n",
    "    # first autocorrelation coefficient of twice-differenced series\n",
    "    diff2_acf1 = acfdiff2x[1]\n",
    "    # Sum of squared of first 10 autocorrelation coefficients of twice-differenced series\n",
    "    diff2_acf10 = np.sum((acfdiff2x[1:11]) ** 2) if size_x > 11 else np.nan\n",
    "\n",
    "    output = {\n",
    "        \"x_acf1\": acf_1,\n",
    "        \"x_acf10\": sum_of_sq_acf10,\n",
    "        \"diff1_acf1\": diff1_acf1,\n",
    "        \"diff1_acf10\": diff1_acf10,\n",
    "        \"diff2_acf1\": diff2_acf1,\n",
    "        \"diff2_acf10\": diff2_acf10,\n",
    "    }\n",
    "\n",
    "    if m > 1:\n",
    "        output[\"seas_acf1\"] = acfx[m] if len(acfx) > m else np.nan\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose\n",
    "\n",
    "from tsfeatures.utils import USAccDeaths, WWWusage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acf_features_seasonal():\n",
    "    z = acf_features(USAccDeaths, 12)\n",
    "    assert isclose(len(z), 7)\n",
    "    assert isclose(z[\"x_acf1\"], 0.70, abs_tol=0.01)\n",
    "    assert isclose(z[\"x_acf10\"], 1.20, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff1_acf1\"], 0.023, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff1_acf10\"], 0.27, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff2_acf1\"], -0.48, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff2_acf10\"], 0.74, abs_tol=0.01)\n",
    "    assert isclose(z[\"seas_acf1\"], 0.62, abs_tol=0.01)\n",
    "\n",
    "\n",
    "test_acf_features_seasonal()\n",
    "\n",
    "\n",
    "def test_acf_features_non_seasonal():\n",
    "    z = acf_features(WWWusage, 1)\n",
    "    assert isclose(len(z), 6)\n",
    "    assert isclose(z[\"x_acf1\"], 0.96, abs_tol=0.01)\n",
    "    assert isclose(z[\"x_acf10\"], 4.19, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff1_acf1\"], 0.79, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff1_acf10\"], 1.40, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff2_acf1\"], 0.17, abs_tol=0.01)\n",
    "    assert isclose(z[\"diff2_acf10\"], 0.33, abs_tol=0.01)\n",
    "\n",
    "\n",
    "test_acf_features_non_seasonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def arch_stat(\n",
    "    x: np.array, freq: int = 1, lags: int = 12, demean: bool = True\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Arch model features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'arch_lm': R^2 value of an autoregressive model of order lags applied to x**2.\n",
    "    \"\"\"\n",
    "    if len(x) <= lags + 1:\n",
    "        return {\"arch_lm\": np.nan}\n",
    "    if demean:\n",
    "         x = x - np.mean(x)\n",
    "\n",
    "    size_x = len(x)\n",
    "    mat = embed(x**2, lags + 1)\n",
    "    X = mat[:, 1:]\n",
    "    y = np.vstack(mat[:, 0])\n",
    "\n",
    "    try:\n",
    "        r_squared = LinearRegression().fit(X, y).score(X, y)\n",
    "    except:\n",
    "        r_squared = np.nan\n",
    "\n",
    "    return {\"arch_lm\": r_squared}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "\n",
    "from tsfeatures.utils import USAccDeaths, WWWusage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_arch_stat_seasonal():\n",
    "    z = arch_stat(USAccDeaths, 12)\n",
    "    test_close(len(z), 1)\n",
    "    test_close(z[\"arch_lm\"], 0.54, eps=0.01)\n",
    "\n",
    "\n",
    "test_arch_stat_seasonal()\n",
    "\n",
    "\n",
    "def test_arch_stat_non_seasonal():\n",
    "    z = arch_stat(WWWusage, 12)\n",
    "    test_close(len(z), 1)\n",
    "    test_close(z[\"arch_lm\"], 0.98, eps=0.01)\n",
    "\n",
    "\n",
    "test_arch_stat_non_seasonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def count_entropy(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Count entropy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'count_entropy': Entropy using only positive data.\n",
    "    \"\"\"\n",
    "    entropy = x[x > 0] * np.log(x[x > 0])\n",
    "    entropy = -entropy.sum()\n",
    "\n",
    "    return {\"count_entropy\": entropy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def crossing_points(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Crossing points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'crossing_points': Number of times that x crosses the median.\n",
    "    \"\"\"\n",
    "    midline = np.median(x)\n",
    "    ab = x <= midline\n",
    "    lenx = len(x)\n",
    "    p1 = ab[: (lenx - 1)]\n",
    "    p2 = ab[1:]\n",
    "    cross = (p1 & (~p2)) | (p2 & (~p1))\n",
    "\n",
    "    return {\"crossing_points\": cross.sum()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def entropy(x: np.array, freq: int = 1, base: float = e) -> Dict[str, float]:\n",
    "    \"\"\"Calculates sample entropy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'entropy': Wrapper of the function spectral_entropy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with np.errstate(divide=\"ignore\"):\n",
    "            entropy = spectral_entropy(x, 1, normalize=True)\n",
    "    except:\n",
    "        entropy = np.nan\n",
    "\n",
    "    return {\"entropy\": entropy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def flat_spots(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Flat spots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'flat_spots': Number of flat spots in x.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cutx = pd.cut(x, bins=10, include_lowest=True, labels=False) + 1\n",
    "    except:\n",
    "        return {\"flat_spots\": np.nan}\n",
    "\n",
    "    rlex = np.array([sum(1 for i in g) for k, g in groupby(cutx)]).max()\n",
    "    return {\"flat_spots\": rlex}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def frequency(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Frequency.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'frequency': Wrapper of freq.\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"frequency\": freq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def guerrero(\n",
    "    x: np.array, freq: int = 1, lower: int = -1, upper: int = 2\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Applies Guerrero's (1993) method to select the lambda which minimises the\n",
    "    coefficient of variation for subseries of x.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series.\n",
    "    lower: float\n",
    "        The lower bound for lambda.\n",
    "    upper: float\n",
    "        The upper bound for lambda.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'guerrero': Minimum coefficient of variation for subseries of x.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] Guerrero, V.M. (1993) Time-series analysis supported by power transformations.\n",
    "        Journal of Forecasting, 12, 37–48.\n",
    "    \"\"\"\n",
    "    func_to_min = lambda lambda_par: lambda_coef_var(lambda_par, x=x, period=freq)\n",
    "\n",
    "    min_ = minimize_scalar(func_to_min, bounds=[lower, upper])\n",
    "    min_ = min_[\"fun\"]\n",
    "\n",
    "    return {\"guerrero\": min_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def heterogeneity(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Heterogeneity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'arch_acf': Sum of squares of the first 12 autocorrelations of the\n",
    "                    residuals of the AR model applied to x\n",
    "        'garch_acf': Sum of squares of the first 12 autocorrelations of the\n",
    "                    residuals of the GARCH model applied to x\n",
    "        'arch_r2': Function arch_stat applied to the residuals of the\n",
    "                   AR model applied to x.\n",
    "        'garch_r2': Function arch_stat applied to the residuals of the GARCH\n",
    "                    model applied to x.\n",
    "    \"\"\"\n",
    "    m = freq\n",
    "\n",
    "    size_x = len(x)\n",
    "    order_ar = min(size_x - 1, np.floor(10 * np.log10(size_x)))\n",
    "    order_ar = int(order_ar)\n",
    "\n",
    "    try:\n",
    "        x_whitened = AR(x).fit(maxlag=order_ar, ic=\"aic\", trend=\"c\").resid\n",
    "    except:\n",
    "        try:\n",
    "            x_whitened = AR(x).fit(maxlag=order_ar, ic=\"aic\", trend=\"nc\").resid\n",
    "        except:\n",
    "            output = {\n",
    "                \"arch_acf\": np.nan,\n",
    "                \"garch_acf\": np.nan,\n",
    "                \"arch_r2\": np.nan,\n",
    "                \"garch_r2\": np.nan,\n",
    "            }\n",
    "\n",
    "            return output\n",
    "    # arch and box test\n",
    "    x_archtest = arch_stat(x_whitened, m)[\"arch_lm\"]\n",
    "    LBstat = (acf(x_whitened**2, nlags=12, fft=False)[1:] ** 2).sum()\n",
    "    # Fit garch model\n",
    "    garch_fit = arch_model(x_whitened, vol=\"GARCH\", rescale=False).fit(disp=\"off\")\n",
    "    # compare arch test before and after fitting garch\n",
    "    garch_fit_std = garch_fit.resid\n",
    "    x_garch_archtest = arch_stat(garch_fit_std, m)[\"arch_lm\"]\n",
    "    # compare Box test of squared residuals before and after fittig.garch\n",
    "    LBstat2 = (acf(garch_fit_std**2, nlags=12, fft=False)[1:] ** 2).sum()\n",
    "\n",
    "    output = {\n",
    "        \"arch_acf\": LBstat,\n",
    "        \"garch_acf\": LBstat2,\n",
    "        \"arch_r2\": x_archtest,\n",
    "        \"garch_r2\": x_garch_archtest,\n",
    "    }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def holt_parameters(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Fitted parameters of a Holt model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'alpha': Level paramater of the Holt model.\n",
    "        'beta': Trend parameter of the Hold model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fit = ExponentialSmoothing(x, trend=\"add\", seasonal=None).fit()\n",
    "        params = {\n",
    "            \"alpha\": fit.params[\"smoothing_level\"],\n",
    "            \"beta\": fit.params[\"smoothing_trend\"],\n",
    "        }\n",
    "    except:\n",
    "        params = {\"alpha\": np.nan, \"beta\": np.nan}\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def hurst(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Hurst index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'hurst': Hurst exponent.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hurst_index = hurst_exponent(x)\n",
    "    except:\n",
    "        hurst_index = np.nan\n",
    "\n",
    "    return {\"hurst\": hurst_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def hw_parameters(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Fitted parameters of a Holt-Winters model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'hw_alpha': Level parameter of the HW model.\n",
    "        'hw_beta': Trend parameter of the HW model.\n",
    "        'hw_gamma': Seasonal parameter of the HW model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fit = ExponentialSmoothing(\n",
    "            x, seasonal_periods=freq, trend=\"add\", seasonal=\"add\"\n",
    "        ).fit()\n",
    "        params = {\n",
    "            \"hw_alpha\": fit.params[\"smoothing_level\"],\n",
    "            \"hw_beta\": fit.params[\"smoothing_trend\"],\n",
    "            \"hw_gamma\": fit.params[\"smoothing_seasonal\"],\n",
    "        }\n",
    "    except:\n",
    "        params = {\"hw_alpha\": np.nan, \"hw_beta\": np.nan, \"hw_gamma\": np.nan}\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def intervals(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Intervals with demand.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'intervals_mean': Mean of intervals with positive values.\n",
    "        'intervals_sd': SD of intervals with positive values.\n",
    "    \"\"\"\n",
    "    x[x > 0] = 1\n",
    "\n",
    "    y = [sum(val) for keys, val in groupby(x, key=lambda k: k != 0) if keys != 0]\n",
    "    y = np.array(y)\n",
    "\n",
    "    return {\"intervals_mean\": np.mean(y), \"intervals_sd\": np.std(y, ddof=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def lumpiness(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"lumpiness.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'lumpiness': Variance of the variances of tiled windows.\n",
    "    \"\"\"\n",
    "    if freq == 1:\n",
    "        width = 10\n",
    "    else:\n",
    "        width = freq\n",
    "\n",
    "    nr = len(x)\n",
    "    lo = np.arange(0, nr, width)\n",
    "    up = lo + width\n",
    "    nsegs = nr / width\n",
    "    varx = [np.nanvar(x[lo[idx] : up[idx]], ddof=1) for idx in np.arange(int(nsegs))]\n",
    "\n",
    "    if len(x) < 2 * width:\n",
    "        lumpiness = 0\n",
    "    else:\n",
    "        lumpiness = np.nanvar(varx, ddof=1)\n",
    "\n",
    "    return {\"lumpiness\": lumpiness}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def nonlinearity(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Nonlinearity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'nonlinearity': 10 t**2/len(x) where t is the statistic used in\n",
    "                        Terasvirta's test.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        test = terasvirta_test(x)\n",
    "        test = 10 * test / len(x)\n",
    "    except:\n",
    "        test = np.nan\n",
    "\n",
    "    return {\"nonlinearity\": test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def pacf_features(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Calculates partial autocorrelation function features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'x_pacf5':  Sum of squares of the first 5 partial autocorrelation\n",
    "                    coefficients.\n",
    "        'diff1x_pacf5': Sum of squares of the first 5 partial autocorrelation\n",
    "                        coefficients of differenced series.\n",
    "        'diff2x_pacf5': Sum of squares of the first 5 partial autocorrelation\n",
    "                        coefficients of twice-differenced series.\n",
    "\n",
    "        Only for seasonal data (freq > 1).\n",
    "        'seas_pacf': Partial autocorrelation\n",
    "                     coefficient at the first seasonal lag.\n",
    "    \"\"\"\n",
    "    m = freq\n",
    "\n",
    "    nlags_ = max(m, 5)\n",
    "\n",
    "    if len(x) > 1:\n",
    "        try:\n",
    "            pacfx = pacf(x, nlags=nlags_, method=\"ldb\")\n",
    "        except:\n",
    "            pacfx = np.nan\n",
    "    else:\n",
    "        pacfx = np.nan\n",
    "    # Sum of first 6 PACs squared\n",
    "    if len(x) > 5 and not np.all(np.isnan(pacfx)):\n",
    "        pacf_5 = np.sum(pacfx[1:6] ** 2)\n",
    "    else:\n",
    "        pacf_5 = np.nan\n",
    "    # Sum of first 5 PACs of difference series squared\n",
    "    if len(x) > 6:\n",
    "        try:\n",
    "            diff1_pacf = pacf(np.diff(x, n=1), nlags=5, method=\"ldb\")[1:6]\n",
    "            diff1_pacf_5 = np.sum(diff1_pacf**2)\n",
    "        except:\n",
    "            diff1_pacf_5 = np.nan\n",
    "    else:\n",
    "        diff1_pacf_5 = np.nan\n",
    "    # Sum of first 5 PACs of twice differenced series squared\n",
    "    if len(x) > 7:\n",
    "        try:\n",
    "            diff2_pacf = pacf(np.diff(x, n=2), nlags=5, method=\"ldb\")[1:6]\n",
    "            diff2_pacf_5 = np.sum(diff2_pacf**2)\n",
    "        except:\n",
    "            diff2_pacf_5 = np.nan\n",
    "    else:\n",
    "        diff2_pacf_5 = np.nan\n",
    "\n",
    "    output = {\n",
    "        \"x_pacf5\": pacf_5,\n",
    "        \"diff1x_pacf5\": diff1_pacf_5,\n",
    "        \"diff2x_pacf5\": diff2_pacf_5,\n",
    "    }\n",
    "\n",
    "    if m > 1:\n",
    "        output[\"seas_pacf\"] = pacfx[m] if len(pacfx) > m else np.nan\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def series_length(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Series length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'series_length': Wrapper of len(x).\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"series_length\": len(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def sparsity(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Sparsity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'sparsity': Average obs with zero values.\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"sparsity\": np.mean(x == 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def stability(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Stability.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'stability': Variance of the means of tiled windows.\n",
    "    \"\"\"\n",
    "    if freq == 1:\n",
    "        width = 10\n",
    "    else:\n",
    "        width = freq\n",
    "\n",
    "    nr = len(x)\n",
    "    lo = np.arange(0, nr, width)\n",
    "    up = lo + width\n",
    "    nsegs = nr / width\n",
    "    meanx = [np.nanmean(x[lo[idx] : up[idx]]) for idx in np.arange(int(nsegs))]\n",
    "\n",
    "    if len(x) < 2 * width:\n",
    "        stability = 0\n",
    "    else:\n",
    "        stability = np.nanvar(meanx, ddof=1)\n",
    "\n",
    "    return {\"stability\": stability}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def stl_features(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Calculates seasonal trend using loess decomposition.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'nperiods': Number of seasonal periods in x.\n",
    "        'seasonal_period': Frequency of the time series.\n",
    "        'trend': Strength of trend.\n",
    "        'spike': Measures \"spikiness\" of x.\n",
    "        'linearity': Linearity of x based on the coefficients of an\n",
    "                     orthogonal quadratic regression.\n",
    "        'curvature': Curvature of x based on the coefficients of an\n",
    "                     orthogonal quadratic regression.\n",
    "        'e_acf1': acfremainder['x_acf1']\n",
    "        'e_acf10': acfremainder['x_acf10']\n",
    "\n",
    "        Only for sesonal data (freq > 0).\n",
    "        'seasonal_strength': Strength of seasonality.\n",
    "        'peak': Strength of peaks.\n",
    "        'trough': Strength of trough.\n",
    "    \"\"\"\n",
    "    m = freq\n",
    "    nperiods = int(m > 1)\n",
    "    # STL fits\n",
    "    if m > 1:\n",
    "        try:\n",
    "            stlfit = STL(x, m, 13).fit()\n",
    "        except:\n",
    "            output = {\n",
    "                \"nperiods\": nperiods,\n",
    "                \"seasonal_period\": m,\n",
    "                \"trend\": np.nan,\n",
    "                \"spike\": np.nan,\n",
    "                \"linearity\": np.nan,\n",
    "                \"curvature\": np.nan,\n",
    "                \"e_acf1\": np.nan,\n",
    "                \"e_acf10\": np.nan,\n",
    "                \"seasonal_strength\": np.nan,\n",
    "                \"peak\": np.nan,\n",
    "                \"trough\": np.nan,\n",
    "            }\n",
    "\n",
    "            return output\n",
    "\n",
    "        trend0 = stlfit.trend\n",
    "        remainder = stlfit.resid\n",
    "        seasonal = stlfit.seasonal\n",
    "    else:\n",
    "        deseas = x\n",
    "        t = np.arange(len(x)) + 1\n",
    "        try:\n",
    "            trend0 = SuperSmoother().fit(t, deseas).predict(t)\n",
    "        except:\n",
    "            output = {\n",
    "                \"nperiods\": nperiods,\n",
    "                \"seasonal_period\": m,\n",
    "                \"trend\": np.nan,\n",
    "                \"spike\": np.nan,\n",
    "                \"linearity\": np.nan,\n",
    "                \"curvature\": np.nan,\n",
    "                \"e_acf1\": np.nan,\n",
    "                \"e_acf10\": np.nan,\n",
    "            }\n",
    "\n",
    "            return output\n",
    "\n",
    "        remainder = deseas - trend0\n",
    "        seasonal = np.zeros(len(x))\n",
    "    # De-trended and de-seasonalized data\n",
    "    detrend = x - trend0\n",
    "    deseason = x - seasonal\n",
    "    fits = x - remainder\n",
    "    # Summay stats\n",
    "    n = len(x)\n",
    "    varx = np.nanvar(x, ddof=1)\n",
    "    vare = np.nanvar(remainder, ddof=1)\n",
    "    vardetrend = np.nanvar(detrend, ddof=1)\n",
    "    vardeseason = np.nanvar(deseason, ddof=1)\n",
    "    # Measure of trend strength\n",
    "    if varx < np.finfo(float).eps:\n",
    "        trend = 0\n",
    "    elif vardeseason / varx < 1e-10:\n",
    "        trend = 0\n",
    "    else:\n",
    "        trend = max(0, min(1, 1 - vare / vardeseason))\n",
    "    # Measure of seasonal strength\n",
    "    if m > 1:\n",
    "        if varx < np.finfo(float).eps:\n",
    "            season = 0\n",
    "        elif np.nanvar(remainder + seasonal, ddof=1) < np.finfo(float).eps:\n",
    "            season = 0\n",
    "        else:\n",
    "            season = max(0, min(1, 1 - vare / np.nanvar(remainder + seasonal, ddof=1)))\n",
    "\n",
    "        peak = (np.argmax(seasonal) + 1) % m\n",
    "        peak = m if peak == 0 else peak\n",
    "\n",
    "        trough = (np.argmin(seasonal) + 1) % m\n",
    "        trough = m if trough == 0 else trough\n",
    "    # Compute measure of spikiness\n",
    "    d = (remainder - np.nanmean(remainder)) ** 2\n",
    "    varloo = (vare * (n - 1) - d) / (n - 2)\n",
    "    spike = np.nanvar(varloo, ddof=1)\n",
    "    # Compute measures of linearity and curvature\n",
    "    time = np.arange(n) + 1\n",
    "    poly_m = poly(time, 2)\n",
    "    time_x = add_constant(poly_m)\n",
    "    coefs = OLS(trend0, time_x).fit().params\n",
    "\n",
    "\n",
    "    try:\n",
    "        linearity = coefs[1]\n",
    "    except:\n",
    "        linearity = np.nan\n",
    "    try:\n",
    "        curvature = -coefs[2]\n",
    "    except:\n",
    "        curvature = np.nan\n",
    "    # ACF features\n",
    "    acfremainder = acf_features(remainder, m)\n",
    "    # Assemble features\n",
    "    output = {\n",
    "        \"nperiods\": nperiods,\n",
    "        \"seasonal_period\": m,\n",
    "        \"trend\": trend,\n",
    "        \"spike\": spike,\n",
    "        \"linearity\": linearity,\n",
    "        \"curvature\": curvature,\n",
    "        \"e_acf1\": acfremainder[\"x_acf1\"],\n",
    "        \"e_acf10\": acfremainder[\"x_acf10\"],\n",
    "    }\n",
    "\n",
    "    if m > 1:\n",
    "        output[\"seasonal_strength\"] = season\n",
    "        output[\"peak\"] = peak\n",
    "        output[\"trough\"] = trough\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def unitroot_kpss(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Unit root kpss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'unitroot_kpss': Statistic for the Kwiatowski et al unit root test.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    nlags = int(4 * (n / 100) ** (1 / 4))\n",
    "\n",
    "    try:\n",
    "        test_kpss, _, _, _ = kpss(x, nlags=nlags)\n",
    "    except:\n",
    "        test_kpss = np.nan\n",
    "\n",
    "    return {\"unitroot_kpss\": test_kpss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def unitroot_pp(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Unit root pp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'unitroot_pp': Statistic for the Phillips-Perron unit root test.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        test_pp = ur_pp(x)\n",
    "    except:\n",
    "        test_pp = np.nan\n",
    "\n",
    "    return {\"unitroot_pp\": test_pp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(x: np.array, freq: int = 1) -> Dict[str, float]:\n",
    "    \"\"\"Computes basic statistics of x.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        The time series.\n",
    "    freq: int\n",
    "        Frequency of the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        'total_sum': Total sum of the series.\n",
    "        'mean': Mean value.\n",
    "        'variance': variance of the time series.\n",
    "        'median': Median value.\n",
    "        'p2point5': 2.5 Percentile.\n",
    "        'p5': 5 percentile.\n",
    "        'p25': 25 percentile.\n",
    "        'p75': 75 percentile.\n",
    "        'p95': 95 percentile.\n",
    "        'p97point5': 97.5 percentile.\n",
    "        'max': Max value.\n",
    "        'min': Min value.\n",
    "    \"\"\"\n",
    "    res = dict(\n",
    "        total_sum=np.sum(x),\n",
    "        mean=np.mean(x),\n",
    "        variance=np.var(x, ddof=1),\n",
    "        median=np.median(x),\n",
    "        p2point5=np.quantile(x, q=0.025),\n",
    "        p5=np.quantile(x, q=0.05),\n",
    "        p25=np.quantile(x, q=0.25),\n",
    "        p75=np.quantile(x, q=0.75),\n",
    "        p95=np.quantile(x, q=0.95),\n",
    "        p97point5=np.quantile(x, q=0.975),\n",
    "        max=np.max(x),\n",
    "        min=np.min(x),\n",
    "    )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def _get_feats(\n",
    "    index,\n",
    "    ts,\n",
    "    freq,\n",
    "    scale=True,\n",
    "    features=[\n",
    "        acf_features,\n",
    "        arch_stat,\n",
    "        crossing_points,\n",
    "        entropy,\n",
    "        flat_spots,\n",
    "        heterogeneity,\n",
    "        holt_parameters,\n",
    "        lumpiness,\n",
    "        nonlinearity,\n",
    "        pacf_features,\n",
    "        stl_features,\n",
    "        stability,\n",
    "        hw_parameters,\n",
    "        unitroot_kpss,\n",
    "        unitroot_pp,\n",
    "        series_length,\n",
    "        hurst,\n",
    "    ],\n",
    "    dict_freqs=FREQS,\n",
    "):\n",
    "    if freq is None:\n",
    "        inf_freq = pd.infer_freq(ts[\"ds\"])\n",
    "        if inf_freq is None:\n",
    "            raise Exception(\n",
    "                \"Failed to infer frequency from the `ds` column, \"\n",
    "                \"please provide the frequency using the `freq` argument.\"\n",
    "            )\n",
    "\n",
    "        freq = dict_freqs.get(inf_freq)\n",
    "        if freq is None:\n",
    "            raise Exception(\n",
    "                \"Error trying to convert infered frequency from the `ds` column \"\n",
    "                \"to integer. Please provide a dictionary with that frequency \"\n",
    "                \"as key and the integer frequency as value. \"\n",
    "                f\"Infered frequency: {inf_freq}\"\n",
    "            )\n",
    "\n",
    "    if isinstance(ts, pd.DataFrame):\n",
    "        assert \"y\" in ts.columns\n",
    "        ts = ts[\"y\"].values\n",
    "\n",
    "    if isinstance(ts, pd.Series):\n",
    "        ts = ts.values\n",
    "\n",
    "    if scale:\n",
    "        ts = scalets(ts)\n",
    "\n",
    "    c_map = ChainMap(\n",
    "        *[dict_feat for dict_feat in [func(ts, freq) for func in features]]\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(dict(c_map), index=[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def tsfeatures(\n",
    "    ts: pd.DataFrame,\n",
    "    freq: Optional[int] = None,\n",
    "    features: List[Callable] = [\n",
    "        acf_features,\n",
    "        arch_stat,\n",
    "        crossing_points,\n",
    "        entropy,\n",
    "        flat_spots,\n",
    "        heterogeneity,\n",
    "        holt_parameters,\n",
    "        lumpiness,\n",
    "        nonlinearity,\n",
    "        pacf_features,\n",
    "        stl_features,\n",
    "        stability,\n",
    "        hw_parameters,\n",
    "        unitroot_kpss,\n",
    "        unitroot_pp,\n",
    "        series_length,\n",
    "        hurst,\n",
    "    ],\n",
    "    dict_freqs: Dict[str, int] = FREQS,\n",
    "    scale: bool = True,\n",
    "    threads: Optional[int] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculates features for time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts: pandas df\n",
    "        Pandas DataFrame with columns ['unique_id', 'ds', 'y'].\n",
    "        Long panel of time series.\n",
    "    freq: int\n",
    "        Frequency of the time series. If None the frequency of\n",
    "        each time series is infered and assigns the seasonal periods according to\n",
    "        dict_freqs.\n",
    "    features: iterable\n",
    "        Iterable of features functions.\n",
    "    scale: bool\n",
    "        Whether (mean-std)scale data.\n",
    "    dict_freqs: dict\n",
    "        Dictionary that maps string frequency of int. Ex: {'D': 7, 'W': 1}\n",
    "    threads: int\n",
    "        Number of threads to use. Use None (default) for parallel processing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas df\n",
    "        Pandas DataFrame where each column is a feature and each row\n",
    "        a time series.\n",
    "    \"\"\"\n",
    "    partial_get_feats = partial(\n",
    "        _get_feats, freq=freq, scale=scale, features=features, dict_freqs=dict_freqs\n",
    "    )\n",
    "\n",
    "    with Pool(threads) as pool:\n",
    "        ts_features = pool.starmap(partial_get_feats, ts.groupby(\"unique_id\"))\n",
    "\n",
    "    ts_features = pd.concat(ts_features).rename_axis(\"unique_id\")\n",
    "    ts_features = ts_features.reset_index()\n",
    "\n",
    "    return ts_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "def _get_feats_wide(index,\n",
    "                    ts,\n",
    "                    scale = True,\n",
    "                    features = [acf_features, arch_stat, crossing_points,\n",
    "                                entropy, flat_spots, heterogeneity, holt_parameters,\n",
    "                                lumpiness, nonlinearity, pacf_features, stl_features,\n",
    "                                stability, hw_parameters, unitroot_kpss, unitroot_pp,\n",
    "                                series_length, hurst]):\n",
    "    seasonality = ts['seasonality'].item()\n",
    "    y = ts['y'].item()\n",
    "    y = np.array(y)\n",
    "\n",
    "    if scale:\n",
    "        y = scalets(y)\n",
    "\n",
    "    c_map = ChainMap(*[dict_feat for dict_feat in [func(y, seasonality) for func in features]])\n",
    "\n",
    "    return pd.DataFrame(dict(c_map), index = [index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "def tsfeatures_wide(ts: pd.DataFrame,\n",
    "                    features: List[Callable] = [acf_features, arch_stat, crossing_points,\n",
    "                                                entropy, flat_spots, heterogeneity,\n",
    "                                                holt_parameters, lumpiness, nonlinearity,\n",
    "                                                pacf_features, stl_features, stability,\n",
    "                                                hw_parameters, unitroot_kpss, unitroot_pp,\n",
    "                                                series_length, hurst],\n",
    "                    scale: bool = True,\n",
    "                    threads: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"Calculates features for time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts: pandas df\n",
    "        Pandas DataFrame with columns ['unique_id', 'seasonality', 'y'].\n",
    "        Wide panel of time series.\n",
    "    features: iterable\n",
    "        Iterable of features functions.\n",
    "    scale: bool\n",
    "        Whether (mean-std)scale data.\n",
    "    threads: int\n",
    "        Number of threads to use. Use None (default) for parallel processing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas df\n",
    "        Pandas DataFrame where each column is a feature and each row\n",
    "        a time series.\n",
    "    \"\"\"\n",
    "    partial_get_feats = partial(_get_feats_wide, scale=scale,\n",
    "                                features=features)\n",
    "\n",
    "    with Pool(threads) as pool:\n",
    "        ts_features = pool.starmap(partial_get_feats, ts.groupby('unique_id'))\n",
    "\n",
    "    ts_features = pd.concat(ts_features).rename_axis('unique_id')\n",
    "    ts_features = ts_features.reset_index()\n",
    "\n",
    "    return ts_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfeatures.m4_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline():\n",
    "    def calculate_features_m4(dataset_name, directory, num_obs=1000000):\n",
    "        _, y_train_df, _, _ = prepare_m4_data(\n",
    "            dataset_name=dataset_name, directory=directory, num_obs=num_obs\n",
    "        )\n",
    "\n",
    "        freq = FREQS[dataset_name[0]]\n",
    "\n",
    "        py_feats = tsfeatures(\n",
    "            y_train_df, freq=freq, features=[count_entropy]\n",
    "        ).set_index(\"unique_id\")\n",
    "\n",
    "    calculate_features_m4(\"Hourly\", \"data\", 100)\n",
    "    calculate_features_m4(\"Daily\", \"data\", 100)\n",
    "\n",
    "test_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
